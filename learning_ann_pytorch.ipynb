{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPGvOtDwoqu1bLxnHD10qnD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/parakram93/ml_foundations/blob/main/learning_ann_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "95YGX_dp1zjX"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.ones(2,3, dtype = torch.double)\n",
        "print(x)\n",
        "print(x.size())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2bia0-er2E7b",
        "outputId": "a8dbbb24-5bef-4843-8b1a-c82ba18aba0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.]], dtype=torch.float64)\n",
            "torch.Size([2, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([2.4,3.5])\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUoeSv6D5bcS",
        "outputId": "7ea6e134-7d0f-4042-db54-38ea969e40a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2.4000, 3.5000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(2,2)\n",
        "y = torch.rand(2,2)\n",
        "print(x)\n",
        "print(y)\n",
        "z = x+y\n",
        "print(z)\n",
        "y.add_(x)\n",
        "print(y)\n",
        "y.mul_(x)\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gpZQjeCi8Wc_",
        "outputId": "7ada6039-55d0-487f-f03b-eef15ffa4123"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.4463, 0.1641],\n",
            "        [0.8269, 0.3761]])\n",
            "tensor([[0.2443, 0.4524],\n",
            "        [0.5560, 0.9381]])\n",
            "tensor([[0.6907, 0.6165],\n",
            "        [1.3829, 1.3142]])\n",
            "tensor([[0.6907, 0.6165],\n",
            "        [1.3829, 1.3142]])\n",
            "tensor([[0.3083, 0.1012],\n",
            "        [1.1436, 0.4942]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(5,3)\n",
        "print(x)\n",
        "print(x[1,1])\n",
        "print(x[1,1].item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "URb-p0Bl9rff",
        "outputId": "94e7c6ea-fa79-49e0-ecd7-7a3242c76068"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.5177, 0.5363, 0.7540],\n",
            "        [0.6485, 0.5692, 0.9753],\n",
            "        [0.4471, 0.4071, 0.5836],\n",
            "        [0.4921, 0.7410, 0.3909],\n",
            "        [0.5675, 0.9212, 0.4181]])\n",
            "tensor(0.5692)\n",
            "0.5692033171653748\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(3,4)\n",
        "y = x.view(4,3)\n",
        "print(y)\n",
        "print(x)\n",
        "z = x.view(-1,3)\n",
        "print(z)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "USUdVPG18zma",
        "outputId": "5583acd9-c66a-4b68-dd8a-047248b035b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.1871, 0.5307, 0.5595],\n",
            "        [0.9632, 0.0411, 0.3116],\n",
            "        [0.2773, 0.3681, 0.9836],\n",
            "        [0.9911, 0.8486, 0.5661]])\n",
            "tensor([[0.1871, 0.5307, 0.5595, 0.9632],\n",
            "        [0.0411, 0.3116, 0.2773, 0.3681],\n",
            "        [0.9836, 0.9911, 0.8486, 0.5661]])\n",
            "tensor([[0.1871, 0.5307, 0.5595],\n",
            "        [0.9632, 0.0411, 0.3116],\n",
            "        [0.2773, 0.3681, 0.9836],\n",
            "        [0.9911, 0.8486, 0.5661]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "85Qbns6m_gZD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.ones(1)\n",
        "b = a.numpy()\n",
        "print(a)\n",
        "print(b)\n",
        "a.add_(2)\n",
        "print(a)\n",
        "print(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "crjj8Pav_j4X",
        "outputId": "36bc7318-a486-4818-baeb-3f06cf9259e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1.])\n",
            "[1.]\n",
            "tensor([3.])\n",
            "[3.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "a = np.ones(5)\n",
        "print(a)\n",
        "b = torch.from_numpy(a)\n",
        "print(b)\n",
        "a += 1\n",
        "\n",
        "print(a)\n",
        "print(b)"
      ],
      "metadata": {
        "id": "_KXSfAMYAJ68"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = np.ones(5)\n",
        "print(a)\n",
        "b = torch.from_numpy(a)\n",
        "print(b)\n",
        "a += 1\n",
        "\n",
        "print(a)\n",
        "print(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dkBfN5YRA3Yv",
        "outputId": "d2a6cba8-2bba-4429-af19-f984a5fb198f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1. 1. 1. 1. 1.]\n",
            "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n",
            "[2. 2. 2. 2. 2.]\n",
            "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():  #Checks whether:, A CUDA-capable GPU exists and PyTorch can access it\n",
        "  device = torch.device(\"cuda\")  #Represents where tensors and models live, All tensors placed on this device will be computed there.\n",
        "  x = torch.ones(5 , device = device) #Creates a tensor directly on GPU, cannot mix with cpu tensors\n",
        "  y = torch.ones(5) # creating tensor in cpu\n",
        "  y = y.to(device) #Copies tensor from CPU memory → GPU memory\n",
        "  z = x+y\n",
        "  z = z.to(\"cpu\") #Moving result back to CPU\n"
      ],
      "metadata": {
        "id": "5F-PTOm8BBHE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "AUTOGRAD"
      ],
      "metadata": {
        "id": "yeglftVvbq4h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn(3,requires_grad=True) #Track every operation involving this tensor so gradients can be computed later. if false, or not written, no backpropagation happens since we cant compute gradients\n",
        "print(x)\n",
        "y = x + 2 #Builds a dynamic computation graph\n",
        "print(y) #PyTorch stores this derivative logic inside AddBackward0(addbackward is in output not in code)\n",
        "z = y*y*2\n",
        "print(z)\n",
        "#z= z.mean() # without calculating mean, backward pass shows error, since it can be computes only in scalar\n",
        "\n",
        "print(z)\n",
        "v = torch.tensor([0.1,0.001,1], dtype = torch.float32) #defining vector for without calculating mean\n",
        "\n",
        "z.backward(v)\n",
        "print(x.grad)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJgxW-CUY-pI",
        "outputId": "ff9ebcc3-d593-46a5-b043-14f4b7aaf80a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0.3051,  2.0009,  0.0212], requires_grad=True)\n",
            "tensor([1.6949, 4.0009, 2.0212], grad_fn=<AddBackward0>)\n",
            "tensor([ 5.7451, 32.0136,  8.1709], grad_fn=<MulBackward0>)\n",
            "tensor([ 5.7451, 32.0136,  8.1709], grad_fn=<MulBackward0>)\n",
            "tensor([0.6779, 0.0160, 8.0850])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor(3.0, requires_grad = True)\n",
        "y = x**2\n",
        "z = torch.sin(y)\n",
        "print(x)\n",
        "print(y)\n",
        "print(z)\n",
        "z.backward()\n",
        "x.grad\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_gZreYflaZ2",
        "outputId": "f4294d09-43d7-40dd-e20c-7ca010852725"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(3., requires_grad=True)\n",
            "tensor(9., grad_fn=<PowBackward0>)\n",
            "tensor(0.4121, grad_fn=<SinBackward0>)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-5.4668)"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor(6.7)\n",
        "y = torch.tensor(0.0)\n",
        "w = torch.tensor(1.0,requires_grad=True)\n",
        "b = torch.tensor(0.0,requires_grad=True)\n",
        "\n",
        "def binary_cross_entropy(prediction,target):\n",
        "  e = 0.00001\n",
        "  prediction = torch.clamp(prediction, e, 1-e)\n",
        "  return -(target*torch.log(prediction)+ (1-target)*torch.log(1-prediction))\n",
        "#forward pass\n",
        "z = w*x +b\n",
        "y_pred = torch.sigmoid(z)\n",
        "loss = binary_cross_entropy(y_pred,y)\n",
        "\n",
        "\n",
        "#backward pass\n",
        "loss.backward()\n",
        "print(w.grad)\n",
        "print(b.grad)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jdqCzrtQgEL8",
        "outputId": "014b64e6-b01d-48b0-d21e-5381ef949ada"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(6.6918)\n",
            "tensor(0.9988)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "gradient descent"
      ],
      "metadata": {
        "id": "-bkN2A5llKZT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "X = torch.tensor([1,2,3,4], dtype = torch.float32)\n",
        "Y = torch.tensor([3,4,5,6], dtype = torch.float32)\n",
        "w = torch.tensor(0.0, requires_grad= True)\n",
        "\n",
        "def forward(x):\n",
        "  return w*x\n",
        "def loss(y, y_pred):\n",
        "    return ((y_pred - y)**2).mean()\n",
        "print(f'Prediction before training: f(5) = {forward(5).item():.3f}') #suru ma 5 halda kati aaucha y ko value\n",
        "learning_rate = 0.01\n",
        "n_iters = 100\n",
        "\n",
        "for epoch in range(n_iters):\n",
        "    # predict = forward pass\n",
        "    y_pred = forward(X)\n",
        "\n",
        "    # loss\n",
        "    l = loss(Y, y_pred)\n",
        "\n",
        "    # calculate gradients = backward pass\n",
        "    l.backward()\n",
        "\n",
        "    # update weights\n",
        "    #w.data = w.data - learning_rate * w.grad\n",
        "    with torch.no_grad():\n",
        "        w -= learning_rate * w.grad\n",
        "\n",
        "    # zero the gradients after updating\n",
        "    w.grad.zero_()\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        print(f'epoch {epoch+1}: w = {w.item():.3f}, loss = {l.item():.8f}')\n",
        "\n",
        "print(f'Prediction after training: f(5) = {forward(5).item():.3f}') # train garera, backprop garera weight ko value adjust gare pachi kati aaucha"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nG-Ddo6alObk",
        "outputId": "caf2940e-ca0b-4814-fe69-d1a0654ae067"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction before training: f(5) = 0.000\n",
            "epoch 1: w = 0.250, loss = 21.50000000\n",
            "epoch 11: w = 1.388, loss = 1.47415674\n",
            "epoch 21: w = 1.612, loss = 0.69796467\n",
            "epoch 31: w = 1.656, loss = 0.66787982\n",
            "epoch 41: w = 1.665, loss = 0.66671371\n",
            "epoch 51: w = 1.666, loss = 0.66666847\n",
            "epoch 61: w = 1.667, loss = 0.66666675\n",
            "epoch 71: w = 1.667, loss = 0.66666669\n",
            "epoch 81: w = 1.667, loss = 0.66666663\n",
            "epoch 91: w = 1.667, loss = 0.66666663\n",
            "Prediction after training: f(5) = 8.333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "X = torch.tensor([1,2,3,4], dtype = torch.float32)\n",
        "Y = torch.tensor([3,4,5,6], dtype = torch.float32)\n",
        "w = torch.tensor(0.0, requires_grad= True)\n",
        "def forward(x):\n",
        "  return w*x\n",
        "print(f'prediction before training {forward(5).item():.3f}')\n",
        "learning_rate = 0.05\n",
        "n_iters = 100\n",
        "loss = nn.MSELoss() #callable function\n",
        "\n",
        "optimizer = torch.optim.Adam([w], lr = learning_rate)\n",
        "for epoch in range(n_iters):\n",
        "  y_predicted = forward(X)\n",
        "  l = loss(Y,y_predicted)\n",
        "  l.backward()\n",
        "  optimizer.step()  #optimizer.step() updates the model parameters using the gradients that were just computed.\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "\n",
        "  if epoch % 10 == 0:\n",
        "        print('epoch ', epoch+1, ': w = ', w, ' loss = ', l)\n",
        "\n",
        "print(f'Prediction after training: f(5) = {forward(5).item():.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dpQhmFp1vwVj",
        "outputId": "ba8a44fe-81e5-404c-b5ad-1cc55862058a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "prediction before training 0.000\n",
            "epoch  1 : w =  tensor(0.0500, requires_grad=True)  loss =  tensor(21.5000, grad_fn=<MseLossBackward0>)\n",
            "epoch  11 : w =  tensor(0.5417, requires_grad=True)  loss =  tensor(10.9839, grad_fn=<MseLossBackward0>)\n",
            "epoch  21 : w =  tensor(0.9902, requires_grad=True)  loss =  tensor(4.5342, grad_fn=<MseLossBackward0>)\n",
            "epoch  31 : w =  tensor(1.3519, requires_grad=True)  loss =  tensor(1.5641, grad_fn=<MseLossBackward0>)\n",
            "epoch  41 : w =  tensor(1.5941, requires_grad=True)  loss =  tensor(0.7289, grad_fn=<MseLossBackward0>)\n",
            "epoch  51 : w =  tensor(1.7137, requires_grad=True)  loss =  tensor(0.6786, grad_fn=<MseLossBackward0>)\n",
            "epoch  61 : w =  tensor(1.7403, requires_grad=True)  loss =  tensor(0.7077, grad_fn=<MseLossBackward0>)\n",
            "epoch  71 : w =  tensor(1.7185, requires_grad=True)  loss =  tensor(0.6893, grad_fn=<MseLossBackward0>)\n",
            "epoch  81 : w =  tensor(1.6864, requires_grad=True)  loss =  tensor(0.6705, grad_fn=<MseLossBackward0>)\n",
            "epoch  91 : w =  tensor(1.6649, requires_grad=True)  loss =  tensor(0.6667, grad_fn=<MseLossBackward0>)\n",
            "Prediction after training: f(5) = 8.291\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "X = torch.tensor([[1], [2], [3], [4]], dtype=torch.float32)\n",
        "Y = torch.tensor([[2], [4], [6], [8]], dtype=torch.float32)\n",
        "n_samples, n_features = X.shape\n",
        "print(f'#samples: {n_samples}, #features: {n_features}')\n",
        "# 0) create a test sample\n",
        "X_test = torch.tensor([5], dtype=torch.float32)\n",
        "input_size = n_features\n",
        "output_size = n_features\n",
        "model = nn.Linear(input_size, output_size) #(n_features, n_neurons)\n",
        "print(f'Prediction before training: f(5) = {model(X_test).item():.3f}')\n",
        "learning_rate = 0.01\n",
        "n_iters = 100\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
        "for epoch in range(n_iters):\n",
        "  y_predicted = model(X)\n",
        "  l = loss(Y,y_predicted)\n",
        "  l.backward()\n",
        "  optimizer.step()  #optimizer.step() updates the model parameters using the gradients that were just computed.\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "\n",
        "  if epoch % 10 == 0:\n",
        "        [w,b] = model.parameters()\n",
        "        print('epoch ', epoch+1, ': w = ', w[0][0].item(), ' loss = ', l)\n",
        "\n",
        "print(f'Prediction after training: f(5) = {model(X_test).item():.3f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7wxTminD-wsd",
        "outputId": "a0b00fdd-70da-45e3-bab6-c6d0af88dcd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#samples: 4, #features: 1\n",
            "Prediction before training: f(5) = -1.121\n",
            "epoch  1 : w =  -0.33344125747680664  loss =  tensor(34.5595, grad_fn=<MseLossBackward0>)\n",
            "epoch  11 : w =  -0.2337193489074707  loss =  tensor(30.4334, grad_fn=<MseLossBackward0>)\n",
            "epoch  21 : w =  -0.1352659910917282  loss =  tensor(26.6204, grad_fn=<MseLossBackward0>)\n",
            "epoch  31 : w =  -0.039030030369758606  loss =  tensor(23.1453, grad_fn=<MseLossBackward0>)\n",
            "epoch  41 : w =  0.05429410934448242  loss =  tensor(20.0150, grad_fn=<MseLossBackward0>)\n",
            "epoch  51 : w =  0.14425520598888397  loss =  tensor(17.2218, grad_fn=<MseLossBackward0>)\n",
            "epoch  61 : w =  0.23057815432548523  loss =  tensor(14.7492, grad_fn=<MseLossBackward0>)\n",
            "epoch  71 : w =  0.3130975663661957  loss =  tensor(12.5759, grad_fn=<MseLossBackward0>)\n",
            "epoch  81 : w =  0.39171287417411804  loss =  tensor(10.6784, grad_fn=<MseLossBackward0>)\n",
            "epoch  91 : w =  0.4663635790348053  loss =  tensor(9.0328, grad_fn=<MseLossBackward0>)\n",
            "Prediction after training: f(5) = 4.108\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "x_numpy,y_numpy = datasets.make_regression(n_samples=100, n_features=1, noise=20, random_state=4)\n",
        "\n",
        "X = torch.from_numpy(x_numpy.astype(np.float32))\n",
        "y = torch.from_numpy(y_numpy.astype(np.float32))\n",
        "y = y.view(y.shape[0],1)\n",
        "\n",
        "n_smaples, n_features = X.shape\n",
        "input_size = n_features\n",
        "output_size = 1\n",
        "\n",
        "model = nn.Linear(input_size, output_size)\n",
        "\n",
        "learning_rate = 0.01\n",
        "n_iter = 100\n",
        "\n",
        "loss = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
        "\n",
        "for epoch in range(n_iter):\n",
        "  y_pred = model(X)\n",
        "  l = loss(y_pred, y)\n",
        "  l.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  if epoch%10 ==0:\n",
        "     print(f'epoch: {epoch+1}, loss = {l.item():.4f}')\n",
        "\n",
        "predicted = model(X).detach().numpy()\n",
        "plt.plot(x_numpy, y_numpy, 'ro')\n",
        "plt.plot(x_numpy, predicted, 'b')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        },
        "id": "V50YdpG0WpGl",
        "outputId": "36c97451-29a7-491c-b943-e2c5d05ef269"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1, loss = 5614.2119\n",
            "epoch: 11, loss = 5599.6636\n",
            "epoch: 21, loss = 5585.1621\n",
            "epoch: 31, loss = 5570.7119\n",
            "epoch: 41, loss = 5556.3154\n",
            "epoch: 51, loss = 5541.9746\n",
            "epoch: 61, loss = 5527.6875\n",
            "epoch: 71, loss = 5513.4526\n",
            "epoch: 81, loss = 5499.2695\n",
            "epoch: 91, loss = 5485.1357\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split #train_test_split (from sklearn.model_selection) splits your dataset into 1.Training set → used to learn parameters, 2. Testing set → used to evaluate performance on unseen data\n",
        "\n",
        "bc = datasets.load_breast_cancer()\n",
        "\n",
        "X,y = bc.data, bc.target\n",
        "\n",
        "n_samples, n_features = X.shape\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234) #test data = 20%, Same split every time you run the code\n",
        "\n",
        "sc = StandardScaler()\n",
        "X_train= sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n",
        "\n",
        "X_train = torch.from_numpy(X_train.astype(np.float32))\n",
        "X_test = torch.from_numpy(X_test.astype(np.float32))\n",
        "y_train = torch.from_numpy(y_train.astype(np.float32))\n",
        "y_test = torch.from_numpy(y_test.astype(np.float32))\n",
        "\n",
        "y_train = y_train.view(y_train.shape[0], 1)\n",
        "y_test = y_test.view(y_test.shape[0], 1)\n",
        "\n",
        "class Model(nn.Module):\n",
        "  def __init__(self,n_input_features):\n",
        "    super(Model,self).__init__()\n",
        "    self.linear = nn.Linear(n_input_features,1)\n",
        "\n",
        "  def forward(self,x):\n",
        "    y_pred = torch.sigmoid(self.linear(x))\n",
        "    return y_pred\n",
        "\n",
        "model = Model(n_features)\n",
        "\n",
        "n_epoch = 100\n",
        "learning_rate = 0.1\n",
        "loss = nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr = learning_rate)\n",
        "\n",
        "for epoch in range(n_epoch):\n",
        "  y_pred = model(X_train)\n",
        "  l = loss(y_pred,y_train)\n",
        "  l.backward()\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  if (epoch+1) % 10 == 0:\n",
        "        print(f'epoch: {epoch+1}, loss = {l.item():.4f}')\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    y_predicted = model(X_test)\n",
        "    y_predicted_cls = y_predicted.round()  #What .round() does : Values ≥ 0.5 → 1, Values < 0.5 → 0\n",
        "    acc = y_predicted_cls.eq(y_test).sum() / float(y_test.shape[0])  #compares y_predicted and y_true and sums no of correct values.  and, accuracy = total correct / total_samples\n",
        "    print(f'accuracy: {acc.item():.4f}')\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "hIbhEcsaNMCI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "557f1757-7945-4660-f4e6-b39bd2c679a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 10, loss = 0.6848\n",
            "epoch: 20, loss = 0.6848\n",
            "epoch: 30, loss = 0.6848\n",
            "epoch: 40, loss = 0.6848\n",
            "epoch: 50, loss = 0.6848\n",
            "epoch: 60, loss = 0.6848\n",
            "epoch: 70, loss = 0.6848\n",
            "epoch: 80, loss = 0.6848\n",
            "epoch: 90, loss = 0.6848\n",
            "epoch: 100, loss = 0.6848\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "class WineDataset(Dataset):\n",
        "\n",
        "  def __init__(self):\n",
        "\n",
        "    xy = np.loadtxt('/content/wine.csv', delimiter = \",\", dtype=np.float32, skiprows = 1)\n",
        "    self.x =torch.from_numpy(xy[:, 1:])\n",
        "    self.y = torch.from_numpy(xy[:, [0]])\n",
        "    self.n_samples = xy.shape[0]\n",
        "\n",
        "\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "     return self.x[index], self.y[index]\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.n_samples\n",
        "\n",
        "dataset = WineDataset()\n",
        "dataloader = DataLoader(dataset = dataset, batch_size = 4, shuffle = True, num_workers = 2) #X_batch.shape = (4, n_features)\n",
        "\n",
        "# dataiter = iter(dataloader)  #  Converts the DataLoader into an iterator,Prepares it to be read batch by batch,I want to manually step through the batches produced by the DataLoade\n",
        "# data = next(dataiter)  #iter(dataloader) returns an object that can produce batches using next(). Fetches one batch from the DataLoader\n",
        "# features, labels = data\n",
        "# print(features, labels)\n",
        "\n",
        "num_epochs = 2\n",
        "total_samples = len(dataset)\n",
        "n_iterations = math.ceil(total_samples/4) #math.ceil means round UP to the nearest integer\n",
        "print(total_samples, n_iterations)\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (inputs, labels) in enumerate(dataloader):\n",
        "\n",
        "        # here: 178 samples, batch_size = 4, n_iters=178/4=44.5 -> 45 iterations\n",
        "        # Run your training process\n",
        "        if (i+1) % 5 == 0:\n",
        "            print(f'Epoch: {epoch+1}/{num_epochs}, Step {i+1}/{n_iterations}| Inputs {inputs.shape} | Labels {labels.shape}')\n",
        "train_dataset = torchvision.datasets.MNIST(root='./data',\n",
        "                                           train=True,\n",
        "                                           transform=torchvision.transforms.ToTensor(),\n",
        "                                           download=True)  #MNIST is a built-in dataset class in torchvision.\n",
        "\n",
        "train_loader = DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=3,\n",
        "                                           shuffle=True)\n",
        "\n",
        "# look at one random sample\n",
        "dataiter = iter(train_loader)\n",
        "data = next(dataiter)\n",
        "inputs, targets = data\n",
        "print(inputs.shape, targets.shape)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3xendE342_Nc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6bac96a-c280-4e80-fbaf-c3f8eaacfd8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "178 45\n",
            "Epoch: 1/2, Step 5/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 10/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 15/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 20/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 25/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 30/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 35/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 40/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 45/45| Inputs torch.Size([2, 13]) | Labels torch.Size([2, 1])\n",
            "Epoch: 2/2, Step 5/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 10/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 15/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 20/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 25/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 30/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 35/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 40/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 45/45| Inputs torch.Size([2, 13]) | Labels torch.Size([2, 1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 59.7MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 1.69MB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 14.7MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 4.47MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 1, 28, 28]) torch.Size([3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  In PyTorch, transforms are used to preprocess and sometimes augment data before it is fed into a neural network. Most commonly,\n",
        "#  they are applied to image datasets using the torchvision.transforms module. Raw images are usually stored as PIL images or NumPy\n",
        "#  arrays with pixel values ranging from 0 to 255, but neural networks expect input data in the form of tensors with normalized values.\n",
        "#   Transforms bridge this gap by converting, scaling, and modifying the data in a consistent and reproducible way.\n",
        "\n",
        "# A very common transform is ToTensor(). This transform converts an image into a PyTorch tensor and scales\n",
        "# its pixel values from the range [0, 255] to [0.0, 1.0]. It also rearranges the image dimensions from height–width–channels\n",
        "#  (H, W, C) to channels–height–width (C, H, W), which is the format PyTorch models expect.\n",
        "\n"
      ],
      "metadata": {
        "id": "jboDApSEku27"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "class WineDataset(Dataset):\n",
        "\n",
        "  def __init__(self, transform = True):\n",
        "\n",
        "    xy = np.loadtxt('/content/wine.csv', delimiter = \",\", dtype=np.float32, skiprows = 1)\n",
        "    self.x =xy[:, 1:]\n",
        "    self.y = xy[:, [0]]\n",
        "    self.n_samples = xy.shape[0]\n",
        "    self.transform = transform\n",
        "\n",
        "\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "     sample =  self.x[index], self.y[index]\n",
        "     if self.transform:\n",
        "      sample = self.transform(sample)\n",
        "     return sample\n",
        "\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.n_samples\n",
        "\n",
        "class ToTensor():\n",
        "  def __call__(self, sample):\n",
        "    inputs, targets = sample\n",
        "    return torch.from_numpy(inputs),torch.from_numpy(targets)\n",
        "class MulTransform():\n",
        "  def __init__(self,factor):\n",
        "    self.factor = factor\n",
        "  def __call__(self,sample):\n",
        "    inputs, targets = sample\n",
        "    inputs *= self.factor\n",
        "    return inputs, targets\n",
        "\n",
        "dataset = WineDataset(transform = ToTensor())\n",
        "first_data = dataset[0]\n",
        "features, labels = first_data\n",
        "print(features)\n",
        "print(type(features), type(labels))\n",
        "\n",
        "composed = torchvision.transforms.Compose([ToTensor(),MulTransform(5)]) #This pipeline converts input data to a tensor and then multiplies it by 4 before feeding it to the model\n",
        "dataset = WineDataset(transform = composed)\n",
        "first_data = dataset[0]\n",
        "features, labels = first_data\n",
        "print(features)\n",
        "print(type(features), type(labels))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OnqGJ3TxjOgg",
        "outputId": "08c11e22-29b3-4d33-a690-6384068eb0cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1.4230e+01, 1.7100e+00, 2.4300e+00, 1.5600e+01, 1.2700e+02, 2.8000e+00,\n",
            "        3.0600e+00, 2.8000e-01, 2.2900e+00, 5.6400e+00, 1.0400e+00, 3.9200e+00,\n",
            "        1.0650e+03])\n",
            "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
            "tensor([7.1150e+01, 8.5500e+00, 1.2150e+01, 7.8000e+01, 6.3500e+02, 1.4000e+01,\n",
            "        1.5300e+01, 1.4000e+00, 1.1450e+01, 2.8200e+01, 5.2000e+00, 1.9600e+01,\n",
            "        5.3250e+03])\n",
            "<class 'torch.Tensor'> <class 'torch.Tensor'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "\n",
        "x_np = np.array([2.0, 1.0, 0.1])\n",
        "x = torch.randn(3, 28*28, requires_grad=True)\n",
        "Y = torch.tensor([2, 0, 1])\n",
        "\n",
        "\n",
        "loss = nn.CrossEntropyLoss()\n",
        "learning_rate = 0.1\n",
        "n_iter = 1000\n",
        "\n",
        "\n",
        "class neural1(nn.Module):\n",
        "  def __init__(self, inputs, neurons,n_classes):\n",
        "    super(neural1,self).__init__()\n",
        "    self.linear = nn.Linear(inputs, neurons, n_classes)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.linear2 = nn.Linear(neurons, n_classes) #for binary classification, n_classes = 1, since its prediction 0 or 1\n",
        "   # self.softmax = nn.softmax(dim = 1)\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.linear(x)\n",
        "    out = self.relu(out)\n",
        "    out = self.linear2(out)\n",
        "    out = torch.sigmoid(out)\n",
        "\n",
        "    return out\n",
        "\n",
        "model = neural1(inputs = 28*28, neurons = 5, n_classes = 3)\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr = learning_rate)\n",
        "\n",
        "for epoch in range(n_iter):\n",
        "\n",
        "    op = model(x)\n",
        "    l_fn = loss(op, Y)\n",
        "    optimizer.zero_grad()\n",
        "    l_fn.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    if epoch % 100 == 0:\n",
        "      print(f'{epoch}')\n",
        "      print(op)\n",
        "      print(l_fn)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "r-HTEzaHHRME",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c1ec8a7-89e1-45f4-d8e1-e0df55f96ec2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "tensor([[0.3914, 0.5306, 0.3977],\n",
            "        [0.3662, 0.6338, 0.3962],\n",
            "        [0.3616, 0.6348, 0.4844]], grad_fn=<SigmoidBackward0>)\n",
            "tensor(1.1039, grad_fn=<NllLossBackward0>)\n",
            "100\n",
            "tensor([[1.3361e-02, 1.4641e-02, 9.8731e-01],\n",
            "        [1.0000e+00, 0.0000e+00, 2.7527e-26],\n",
            "        [0.0000e+00, 1.0000e+00, 0.0000e+00]], grad_fn=<SigmoidBackward0>)\n",
            "tensor(0.5552, grad_fn=<NllLossBackward0>)\n",
            "200\n",
            "tensor([[5.4400e-03, 5.9776e-03, 9.9477e-01],\n",
            "        [1.0000e+00, 0.0000e+00, 6.7492e-26],\n",
            "        [0.0000e+00, 1.0000e+00, 0.0000e+00]], grad_fn=<SigmoidBackward0>)\n",
            "tensor(0.5530, grad_fn=<NllLossBackward0>)\n",
            "300\n",
            "tensor([[3.0926e-03, 3.4000e-03, 9.9701e-01],\n",
            "        [1.0000e+00, 0.0000e+00, 1.1856e-25],\n",
            "        [0.0000e+00, 1.0000e+00, 0.0000e+00]], grad_fn=<SigmoidBackward0>)\n",
            "tensor(0.5523, grad_fn=<NllLossBackward0>)\n",
            "400\n",
            "tensor([[2.0390e-03, 2.2421e-03, 9.9803e-01],\n",
            "        [1.0000e+00, 0.0000e+00, 1.7972e-25],\n",
            "        [0.0000e+00, 1.0000e+00, 0.0000e+00]], grad_fn=<SigmoidBackward0>)\n",
            "tensor(0.5520, grad_fn=<NllLossBackward0>)\n",
            "500\n",
            "tensor([[1.4632e-03, 1.6090e-03, 9.9858e-01],\n",
            "        [1.0000e+00, 0.0000e+00, 2.5037e-25],\n",
            "        [0.0000e+00, 1.0000e+00, 0.0000e+00]], grad_fn=<SigmoidBackward0>)\n",
            "tensor(0.5519, grad_fn=<NllLossBackward0>)\n",
            "600\n",
            "tensor([[1.1093e-03, 1.2198e-03, 9.9893e-01],\n",
            "        [1.0000e+00, 0.0000e+00, 3.3019e-25],\n",
            "        [0.0000e+00, 1.0000e+00, 0.0000e+00]], grad_fn=<SigmoidBackward0>)\n",
            "tensor(0.5518, grad_fn=<NllLossBackward0>)\n",
            "700\n",
            "tensor([[8.7390e-04, 9.6101e-04, 9.9915e-01],\n",
            "        [1.0000e+00, 0.0000e+00, 4.1906e-25],\n",
            "        [0.0000e+00, 1.0000e+00, 0.0000e+00]], grad_fn=<SigmoidBackward0>)\n",
            "tensor(0.5517, grad_fn=<NllLossBackward0>)\n",
            "800\n",
            "tensor([[7.0834e-04, 7.7895e-04, 9.9931e-01],\n",
            "        [1.0000e+00, 0.0000e+00, 5.1696e-25],\n",
            "        [0.0000e+00, 1.0000e+00, 0.0000e+00]], grad_fn=<SigmoidBackward0>)\n",
            "tensor(0.5516, grad_fn=<NllLossBackward0>)\n",
            "900\n",
            "tensor([[5.8684e-04, 6.4534e-04, 9.9943e-01],\n",
            "        [1.0000e+00, 0.0000e+00, 6.2395e-25],\n",
            "        [0.0000e+00, 1.0000e+00, 0.0000e+00]], grad_fn=<SigmoidBackward0>)\n",
            "tensor(0.5516, grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "input_size = 784  # 28x28\n",
        "hidden_size = 500\n",
        "num_classes = 10 #how many discinct ans the model allowed to give\n",
        "num_epochs = 2\n",
        "batch_size = 100\n",
        "learning_rate = 0.001\n",
        "\n",
        "train_dataset = torchvision.datasets.MNIST(root='./data',\n",
        "                                           train=True,\n",
        "                                           transform=transforms.ToTensor(),\n",
        "                                           download=True)\n",
        "\n",
        "test_dataset = torchvision.datasets.MNIST(root='./data',\n",
        "                                          train=False,\n",
        "                                          transform=transforms.ToTensor())\n",
        "\n",
        "# Data loader\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False)\n",
        "# examples = iter(test_loader)\n",
        "# example_data, example_targets = next(examples)\n",
        "\n",
        "# for i in range(6):\n",
        "#     plt.subplot(2,3,i+1)\n",
        "#     plt.imshow(example_data[i][0], cmap='gray')\n",
        "# plt.show()\n",
        "\n",
        "class neuralnet(nn.Module):\n",
        "  def  __init__(self, input_size, hidden_size, num_classes):\n",
        "    super(neuralnet,self).__init__()\n",
        "    self.input_size = input_size\n",
        "    self.l1 = nn.Linear(input_size,hidden_size)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.l2 = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "  def forward(self,x):\n",
        "    out = self.l1(x)\n",
        "    out = self.relu(out)\n",
        "    out = self.l2(out)\n",
        "    #no activation at and\n",
        "    return out\n",
        "\n",
        "model = neuralnet(input_size, hidden_size, num_classes).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "n_total_steps = len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "  for i, (images,labels) in enumerate(train_loader):\n",
        "    images = images.reshape(-1, 28*28).to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    outputs= model(images)\n",
        "    loss = criterion(outputs, labels)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (i+1)%100 == 0:\n",
        "      print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')\n",
        "\n",
        "  with torch.no_grad():\n",
        "    n_correct = 0\n",
        "    n_samples = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.reshape(-1, 28*28).to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        # max returns (value ,index)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        n_samples += labels.size(0)\n",
        "        n_correct += (predicted == labels).sum().item()\n",
        "\n",
        "    acc = 100.0 * n_correct / n_samples\n",
        "    print(f'Accuracy of the network on the 10000 test images: {acc} %')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OEqTCIGDvzLO",
        "outputId": "3d3f0669-e858-4844-fdc4-7f9135775c76"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 109MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 41.4MB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 107MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 9.25MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/2], Step [100/600], Loss: 0.3387\n",
            "Epoch [1/2], Step [200/600], Loss: 0.1338\n",
            "Epoch [1/2], Step [300/600], Loss: 0.3829\n",
            "Epoch [1/2], Step [400/600], Loss: 0.2434\n",
            "Epoch [1/2], Step [500/600], Loss: 0.1482\n",
            "Epoch [1/2], Step [600/600], Loss: 0.1982\n",
            "Accuracy of the network on the 10000 test images: 95.59 %\n",
            "Epoch [2/2], Step [100/600], Loss: 0.1002\n",
            "Epoch [2/2], Step [200/600], Loss: 0.1295\n",
            "Epoch [2/2], Step [300/600], Loss: 0.0712\n",
            "Epoch [2/2], Step [400/600], Loss: 0.0518\n",
            "Epoch [2/2], Step [500/600], Loss: 0.0377\n",
            "Epoch [2/2], Step [600/600], Loss: 0.1373\n",
            "Accuracy of the network on the 10000 test images: 97.01 %\n"
          ]
        }
      ]
    }
  ]
}