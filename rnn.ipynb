{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMG+ngb3EZfHOHYSEhrXPMf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/parakram93/ml_foundations/blob/main/rnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_Lu7-Uqo5-Z",
        "outputId": "de42c572-cbce-4618-e06e-a6ce5695a55d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape : torch.Size([1, 3, 3])\n",
            "Output shape : torch.Size([1, 3, 2])\n",
            "Hidden shape : torch.Size([3, 1, 5])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class SimpleRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(SimpleRNN, self).__init__()\n",
        "        self.rnn = nn.RNN(input_size=input_size, hidden_size=hidden_size,num_layers=3, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, h = self.rnn(x)\n",
        "        out = self.fc(out)\n",
        "        return out, h\n",
        "\n",
        "# Dummy input: 1 batch, 3 words, 3 features per word\n",
        "sentence = torch.tensor([\n",
        "    [ [1.0, 0.0, 0.0],\n",
        "      [0.0, 1.0, 0.0],\n",
        "      [0.5, 0.5, 0.0] ]\n",
        "], dtype=torch.float)   # always good to specify float\n",
        "\n",
        "\n",
        "print(\"Input shape :\", sentence.shape)\n",
        "\n",
        "model = SimpleRNN(input_size=3, hidden_size=5, output_size=2)\n",
        "outputs, hidden = model.forward(sentence)\n",
        "\n",
        "print(\"Output shape :\", outputs.shape)\n",
        "print(\"Hidden shape :\", hidden.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('100_Unique_QA_Dataset.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "3WxzjZriQ99c",
        "outputId": "644aac47-00f2-45ec-9242-b7d885435437"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          question      answer\n",
              "0                   What is the capital of France?       Paris\n",
              "1                  What is the capital of Germany?      Berlin\n",
              "2               Who wrote 'To Kill a Mockingbird'?  Harper-Lee\n",
              "3  What is the largest planet in our solar system?     Jupiter\n",
              "4   What is the boiling point of water in Celsius?         100"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-39afb774-f13f-420f-8ea0-283e7d8b5705\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What is the capital of France?</td>\n",
              "      <td>Paris</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What is the capital of Germany?</td>\n",
              "      <td>Berlin</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Who wrote 'To Kill a Mockingbird'?</td>\n",
              "      <td>Harper-Lee</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What is the largest planet in our solar system?</td>\n",
              "      <td>Jupiter</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What is the boiling point of water in Celsius?</td>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-39afb774-f13f-420f-8ea0-283e7d8b5705')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-39afb774-f13f-420f-8ea0-283e7d8b5705 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-39afb774-f13f-420f-8ea0-283e7d8b5705');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 90,\n  \"fields\": [\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 90,\n        \"samples\": [\n          \"What is the currency of China?\",\n          \"What is the capital of Australia?\",\n          \"Who discovered electricity?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 85,\n        \"samples\": [\n          \"ChristopherColumbus\",\n          \"Paris\",\n          \"Christmas\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#tokenize\n",
        "def tokenize(text):\n",
        "  text = text.lower()\n",
        "  text = text.replace('?','')\n",
        "  text = text.replace(\"'\",'')\n",
        "  return text.split()\n",
        "\n",
        "tokenize(\"hello world?\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mv91d-ZBR8fR",
        "outputId": "c12f0c11-2b26-4a71-a668-0f05d921c6fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['hello', 'world']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#vocab\n",
        "vocab = {'<UNK>':0}\n"
      ],
      "metadata": {
        "id": "HBJ-B91qWRhz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_vocab(row):\n",
        "  tokenized_question = tokenize(row['question'])\n",
        "  tokenized_answer = tokenize(row['answer'])\n",
        "\n",
        "  merged_tokens = tokenized_question + tokenized_answer\n",
        "  for token in merged_tokens:\n",
        "\n",
        "    if token not in vocab:\n",
        "      vocab[token] = len(vocab)\n"
      ],
      "metadata": {
        "id": "GDQddrbFYI-J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.apply(build_vocab, axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "PU6iZJkmYQX2",
        "outputId": "bedd95ce-33c2-4ecc-f5a0-ed4d7efb55bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     None\n",
              "1     None\n",
              "2     None\n",
              "3     None\n",
              "4     None\n",
              "      ... \n",
              "85    None\n",
              "86    None\n",
              "87    None\n",
              "88    None\n",
              "89    None\n",
              "Length: 90, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85</th>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87</th>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88</th>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89</th>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>90 rows × 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert words to numerical indices\n",
        "def text_to_indices(text, vocab):\n",
        "\n",
        "  indexed_text = []\n",
        "\n",
        "  for token in tokenize(text):\n",
        "\n",
        "    if token in vocab:\n",
        "      indexed_text.append(vocab[token])\n",
        "    else:\n",
        "      indexed_text.append(vocab['<UNK>'])\n",
        "\n",
        "  return indexed_text"
      ],
      "metadata": {
        "id": "YRqBAt-IamJs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_to_indices(\"Hello world\", vocab)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cVkf26_Zam9_",
        "outputId": "1d5543a5-1eca-4f71-a9cd-999b7ead327b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 45]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "metadata": {
        "id": "VsnBGoiodD-8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class QADataset(Dataset):\n",
        "\n",
        "  def __init__(self,df,vocab):\n",
        "    self.df = df\n",
        "    self.vocab = vocab\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.df.shape[0]\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    numerical_question = text_to_indices(self.df.iloc[index]['question'], self.vocab)\n",
        "    numerical_answer = text_to_indices(self.df.iloc[index]['answer'], self.vocab)\n",
        "    return torch.tensor(numerical_question), torch.tensor(numerical_answer)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3BRnfxZgdFZh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = QADataset(df, vocab)"
      ],
      "metadata": {
        "id": "XGMpXXOshLD_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)"
      ],
      "metadata": {
        "id": "ZdNof6HohQeM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for question, answer in dataloader:\n",
        "  print(question, answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "epzsAUYAhVbV",
        "outputId": "38e93395-af63-4943-9d0a-7efc370fa449"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[  1,   2,   3, 146, 147,  19, 148]]) tensor([[149]])\n",
            "tensor([[ 1,  2,  3,  4,  5, 53]]) tensor([[54]])\n",
            "tensor([[  1,   2,   3, 180, 181, 182, 183]]) tensor([[184]])\n",
            "tensor([[  1,   2,   3,   4,   5, 135]]) tensor([[136]])\n",
            "tensor([[ 78,  79, 129,  81,  19,   3,  21,  22]]) tensor([[36]])\n",
            "tensor([[42, 43, 44, 45, 46, 47, 48]]) tensor([[49]])\n",
            "tensor([[ 42, 101,   2,   3,  17]]) tensor([[102]])\n",
            "tensor([[ 42, 312,   2, 313,  62,  63,   3, 314, 315]]) tensor([[316]])\n",
            "tensor([[ 1,  2,  3, 92, 93, 94]]) tensor([[95]])\n",
            "tensor([[ 42, 216, 118, 217, 218,  19,  14, 219,  43]]) tensor([[220]])\n",
            "tensor([[ 1,  2,  3,  4,  5, 73]]) tensor([[74]])\n",
            "tensor([[10,  2,  3, 66,  5, 67]]) tensor([[68]])\n",
            "tensor([[ 42,  18,   2,   3, 281,  12,   3, 282]]) tensor([[205]])\n",
            "tensor([[10, 55,  3, 56,  5, 57]]) tensor([[58]])\n",
            "tensor([[  1,   2,   3, 103,   5, 104,  19, 105]]) tensor([[106]])\n",
            "tensor([[ 42,  86,  87, 241, 242,  19,  39, 243]]) tensor([[244]])\n",
            "tensor([[ 10,  75,   3, 296,  19, 297]]) tensor([[298]])\n",
            "tensor([[  1,   2,   3,  37, 133,   5,  26]]) tensor([[134]])\n",
            "tensor([[  1,   2,   3,  33,  34,   5, 245]]) tensor([[246]])\n",
            "tensor([[ 42, 137,   2, 138,  39, 139]]) tensor([[53]])\n",
            "tensor([[ 42, 137, 118,   3, 247,   5, 248]]) tensor([[249]])\n",
            "tensor([[ 10, 140,   3, 141, 270,  93, 271,   5,   3, 272]]) tensor([[273]])\n",
            "tensor([[ 42, 117, 118,   3, 119,  94, 120]]) tensor([[121]])\n",
            "tensor([[1, 2, 3, 4, 5, 6]]) tensor([[7]])\n",
            "tensor([[ 42, 137,   2, 226,  12,   3, 227, 228]]) tensor([[155]])\n",
            "tensor([[ 42,   2,   3, 210, 137, 168, 211, 169]]) tensor([[113]])\n",
            "tensor([[10, 96,  3, 97]]) tensor([[98]])\n",
            "tensor([[  1,   2,   3, 221,   5, 222, 223, 224]]) tensor([[225]])\n",
            "tensor([[  1,   2,   3,   4,   5, 279]]) tensor([[280]])\n",
            "tensor([[  1,   2,   3,  17, 115,  83,  84]]) tensor([[116]])\n",
            "tensor([[ 1,  2,  3, 59, 25,  5, 26, 19, 60]]) tensor([[61]])\n",
            "tensor([[ 78,  79, 261, 151,  14, 262, 153]]) tensor([[36]])\n",
            "tensor([[ 78,  79, 195,  81,  19,   3, 196, 197, 198]]) tensor([[199]])\n",
            "tensor([[ 1,  2,  3, 33, 34,  5, 35]]) tensor([[36]])\n",
            "tensor([[ 1,  2,  3, 17, 18, 19, 20, 21, 22]]) tensor([[23]])\n",
            "tensor([[ 1,  2,  3, 69,  5, 53]]) tensor([[260]])\n",
            "tensor([[  1,   2,   3,  92, 137,  19,   3,  45]]) tensor([[185]])\n",
            "tensor([[ 10,  11, 189, 158, 190]]) tensor([[191]])\n",
            "tensor([[ 42, 250, 251, 118, 252, 253]]) tensor([[254]])\n",
            "tensor([[ 10, 308,   3, 309, 310]]) tensor([[311]])\n",
            "tensor([[ 42, 137,   2,  62,  39,   3, 322, 323]]) tensor([[6]])\n",
            "tensor([[ 10,  75, 208]]) tensor([[209]])\n",
            "tensor([[  1,   2,   3,   4,   5, 109]]) tensor([[317]])\n",
            "tensor([[  1,   2,   3,   4,   5, 236, 237]]) tensor([[238]])\n",
            "tensor([[ 1,  2,  3, 50, 51, 19,  3, 45]]) tensor([[52]])\n",
            "tensor([[ 42,  18, 118,   3, 186, 187]]) tensor([[188]])\n",
            "tensor([[  1,  87, 229, 230, 231, 232]]) tensor([[233]])\n",
            "tensor([[ 10, 140,   3, 141, 171,   5,   3,  70, 172]]) tensor([[173]])\n",
            "tensor([[ 10,  11, 157, 158, 159]]) tensor([[160]])\n",
            "tensor([[10, 11, 12, 13, 14, 15]]) tensor([[16]])\n",
            "tensor([[ 10,  75, 111]]) tensor([[112]])\n",
            "tensor([[  1,   2,   3,   4,   5, 113]]) tensor([[114]])\n",
            "tensor([[42, 18,  2, 62, 63,  3, 64, 18]]) tensor([[65]])\n",
            "tensor([[ 1,  2,  3, 69,  5,  3, 70, 71]]) tensor([[72]])\n",
            "tensor([[ 10,  96,   3, 104, 239]]) tensor([[240]])\n",
            "tensor([[ 42, 200,   2,  14, 201, 202, 203, 204]]) tensor([[205]])\n",
            "tensor([[ 1,  2,  3, 24, 25,  5, 26, 19, 27]]) tensor([[28]])\n",
            "tensor([[  1,   2,   3, 163, 164, 165,  83,  84]]) tensor([[166]])\n",
            "tensor([[10, 29,  3, 30, 31]]) tensor([[32]])\n",
            "tensor([[  1,   2,   3,   4,   5, 206]]) tensor([[207]])\n",
            "tensor([[  1,   2,   3, 141, 117,  83,   3, 277, 278]]) tensor([[121]])\n",
            "tensor([[  1,   2,   3,   4,   5, 286]]) tensor([[287]])\n",
            "tensor([[  1,   2,   3, 212,   5,  14, 213, 214]]) tensor([[215]])\n",
            "tensor([[  1,   2,   3, 122, 123,  19,   3,  45]]) tensor([[124]])\n",
            "tensor([[ 42, 255,   2, 256,  83, 257, 258]]) tensor([[259]])\n",
            "tensor([[ 42, 137,   2, 138,  39, 175, 269]]) tensor([[99]])\n",
            "tensor([[ 42, 174,   2,  62,  39, 175, 176,  12, 177, 178]]) tensor([[179]])\n",
            "tensor([[1, 2, 3, 4, 5, 8]]) tensor([[9]])\n",
            "tensor([[ 78,  79, 150, 151,  14, 152, 153]]) tensor([[154]])\n",
            "tensor([[ 42, 290, 291, 118, 292, 158, 293, 294]]) tensor([[295]])\n",
            "tensor([[78, 79, 80, 81, 82, 83, 84]]) tensor([[85]])\n",
            "tensor([[ 42, 263, 264,  14, 265, 266, 158, 267]]) tensor([[268]])\n",
            "tensor([[  1,   2,   3,  69,   5, 155]]) tensor([[156]])\n",
            "tensor([[  1,   2,   3, 146,  86,  19, 192, 193]]) tensor([[194]])\n",
            "tensor([[ 78,  79, 288,  81,  19,  14, 289]]) tensor([[85]])\n",
            "tensor([[ 10,   2,  62,  63,   3, 283,   5, 284]]) tensor([[285]])\n",
            "tensor([[ 1,  2,  3, 37, 38, 39, 40]]) tensor([[41]])\n",
            "tensor([[ 10, 140,   3, 141, 142,  12, 143,  83,   3, 144]]) tensor([[145]])\n",
            "tensor([[  1,   2,   3,  37,  38,  39, 161]]) tensor([[162]])\n",
            "tensor([[ 42, 107,   2, 108,  19, 109]]) tensor([[110]])\n",
            "tensor([[ 42, 299, 300, 118,  14, 301, 302, 158, 303, 304, 305, 306]]) tensor([[307]])\n",
            "tensor([[ 42, 318,   2,  62,  63,   3, 319,   5, 320]]) tensor([[321]])\n",
            "tensor([[ 1,  2,  3,  4,  5, 99]]) tensor([[100]])\n",
            "tensor([[ 10,  29, 130, 131]]) tensor([[132]])\n",
            "tensor([[ 42, 125,   2,  62,  63,   3, 126, 127]]) tensor([[128]])\n",
            "tensor([[42, 86, 87, 88, 89, 39, 90]]) tensor([[91]])\n",
            "tensor([[10, 75, 76]]) tensor([[77]])\n",
            "tensor([[  1,   2,   3, 234,   5, 235]]) tensor([[131]])\n",
            "tensor([[ 42,   2,   3, 274, 211, 275]]) tensor([[276]])\n",
            "tensor([[ 42, 167,   2,   3,  17, 168, 169]]) tensor([[170]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "IkE0kzAQjAP9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleRNN(nn.Module):\n",
        "\n",
        "  def __init__(self, vocab_size):\n",
        "    super().__init__()\n",
        "    self.embedding = nn.Embedding(vocab_size, embedding_dim=50)\n",
        "    self.rnn = nn.RNN(50, 64, batch_first=True)\n",
        "    self.fc = nn.Linear(64, vocab_size)\n",
        "\n",
        "  def forward(self, question):\n",
        "    embedded_question = self.embedding(question)\n",
        "    hidden, final = self.rnn(embedded_question)\n",
        "    output = self.fc(final.squeeze(0))\n",
        "\n",
        "    return output"
      ],
      "metadata": {
        "id": "HHmyemKbjB6B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = nn.Embedding(324, embedding_dim=50)\n",
        "z =dataset[10][0]\n",
        "b = y(z)\n",
        "x = nn.RNN(50,64,batch_first=True)\n",
        "c,d = x(b)\n",
        "print(c.shape)\n",
        "print(d.shape)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y0svWIURy6LA",
        "outputId": "bd5e4a0c-f4b5-4dad-f9e3-8b644ca277e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([6, 64])\n",
            "torch.Size([1, 64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.001\n",
        "epochs = 20"
      ],
      "metadata": {
        "id": "OqqAmxID4gor"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SimpleRNN(len(vocab))\n",
        "a_loss = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n"
      ],
      "metadata": {
        "id": "Mlgpnm2t4L13"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "  total_loss = 0\n",
        "\n",
        "  for question, answer in dataloader:\n",
        "\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    output = model.forward(question)\n",
        "\n",
        "    loss = a_loss(output,answer[0])\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    total_loss += loss.item()\n",
        "\n",
        "  print(f\"Epoch: {epoch+1}, Loss: {total_loss:4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1HCubu4A4oby",
        "outputId": "5cc6898c-31d6-4e40-d261-d4fc2a59cc74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Loss: 525.842284\n",
            "Epoch: 2, Loss: 457.881875\n",
            "Epoch: 3, Loss: 376.598355\n",
            "Epoch: 4, Loss: 315.051475\n",
            "Epoch: 5, Loss: 263.519734\n",
            "Epoch: 6, Loss: 215.883261\n",
            "Epoch: 7, Loss: 171.027251\n",
            "Epoch: 8, Loss: 132.660964\n",
            "Epoch: 9, Loss: 102.131030\n",
            "Epoch: 10, Loss: 77.890881\n",
            "Epoch: 11, Loss: 61.028518\n",
            "Epoch: 12, Loss: 46.996479\n",
            "Epoch: 13, Loss: 37.436921\n",
            "Epoch: 14, Loss: 30.527876\n",
            "Epoch: 15, Loss: 24.958444\n",
            "Epoch: 16, Loss: 20.781418\n",
            "Epoch: 17, Loss: 17.620165\n",
            "Epoch: 18, Loss: 14.998881\n",
            "Epoch: 19, Loss: 13.090411\n",
            "Epoch: 20, Loss: 11.259684\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(model,question,threshold = 0.5):\n",
        "  numerical_question = text_to_indices(question, vocab)\n",
        "  question_tensor = torch.tensor(numerical_question).unsqueeze(0)\n",
        "  output = model(question_tensor)\n",
        "  probs = torch.nn.functional.softmax(output, dim=1)\n",
        "  value, index = torch.max(probs, dim=1)\n",
        "  if value < threshold:\n",
        "    print(\"I don't know\")\n",
        "  print(list(vocab.keys())[index])"
      ],
      "metadata": {
        "id": "aTIzmzqcDZNT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict(model,\"What id your name?\")"
      ],
      "metadata": {
        "id": "GsA8_FrCFzTG",
        "outputId": "76c623d4-9740-45ba-b7dd-bfd66396d137",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I don't know\n",
            "batman\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy<2\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DY7Ygzhptx-u",
        "outputId": "67a27afd-2fdc-4249-b6f9-019abc22fbfc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: 2: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "\n",
        "# -------------------------\n",
        "# 1. Prepare Data\n",
        "# -------------------------\n",
        "data = \"hello world\"\n",
        "chars = sorted(list(set(data)))\n",
        "vocab_size = len(chars)\n",
        "\n",
        "stoi = {ch: i for i, ch in enumerate(chars)}\n",
        "itos = {i: ch for ch, i in stoi.items()}\n",
        "\n",
        "def encode(s):\n",
        "    return [stoi[c] for c in data]\n",
        "\n",
        "def decode(idxs):\n",
        "    return \"\".join(itos[i] for i in idxs)\n",
        "\n",
        "encoded = encode(data)\n",
        "input_ids  = torch.tensor(encoded[:-1])\n",
        "target_ids = torch.tensor(encoded[1:])   # next-char prediction\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# 2. Define RNN Model (PyTorch built-in)\n",
        "# -------------------------\n",
        "class CharRNN(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_size=32, hidden_size=64):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, emb_size)\n",
        "        self.rnn = nn.RNN(emb_size, hidden_size, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
        "\n",
        "    def forward(self, x, h):\n",
        "        x = self.embedding(x)          # (B, T, emb)\n",
        "        out, h = self.rnn(x, h)        # (B, T, hidden)\n",
        "        logits = self.fc(out)          # (B, T, vocab)\n",
        "        return logits, h\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return torch.zeros(1, 1, 64)   # (num_layers, batch, hidden)\n",
        "\n",
        "\n",
        "model = CharRNN(vocab_size)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# 3. Training\n",
        "# -------------------------\n",
        "num_epochs = 500\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    h = model.init_hidden()\n",
        "    x = input_ids.unsqueeze(0)      # (1, T)\n",
        "    y = target_ids.unsqueeze(0)     # (1, T)\n",
        "\n",
        "    logits, h = model(x, h)\n",
        "    loss = criterion(logits.view(-1, vocab_size), y.view(-1))\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 100 == 0:\n",
        "        print(f\"Epoch {epoch} | Loss = {loss.item():.4f}\")\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# 4. Sampling / Text Generation\n",
        "# -------------------------\n",
        "def sample(start_char='h', length=40):\n",
        "    model.eval()\n",
        "    idx = torch.tensor([[stoi[start_char]]])\n",
        "    h = model.init_hidden()\n",
        "\n",
        "    output_string = start_char\n",
        "\n",
        "    for _ in range(length):\n",
        "        logits, h = model(idx, h)\n",
        "        probs = torch.softmax(logits[0, -1], dim=0).detach().numpy()\n",
        "        next_idx = np.random.choice(vocab_size, p=probs)\n",
        "\n",
        "        output_string += itos[next_idx]\n",
        "        idx = torch.tensor([[next_idx]])\n",
        "\n",
        "    return output_string\n",
        "\n",
        "\n",
        "print(\"\\nGenerated text:\")\n",
        "print(sample(\"h\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "necAzWKASNJb",
        "outputId": "9578cf7b-0101-4396-9e5d-132beec967f2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 | Loss = 2.0790\n",
            "Epoch 100 | Loss = 0.0003\n",
            "Epoch 200 | Loss = 0.0002\n",
            "Epoch 300 | Loss = 0.0001\n",
            "Epoch 400 | Loss = 0.0001\n",
            "\n",
            "Generated text:\n",
            "hello worldo worldo worldo worldo worldo \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torchtext==0.16.2\n"
      ],
      "metadata": {
        "id": "9RkB7-hDnfY1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from datasets import load_dataset\n",
        "\n",
        "# Sample dataset\n",
        "sentences = [\n",
        "    \"I love this movie\",\n",
        "    \"This film is great\",\n",
        "    \"I hate this movie\",\n",
        "    \"This  is terrible\"\n",
        "]\n",
        "\n",
        "labels = [1, 1, 0, 0]\n",
        "\n",
        "# 1. Tokenize sentences (split words)\n",
        "def tokenize(sentence):\n",
        "    return sentence.lower().split()\n",
        "\n",
        "tokenized_sentences = [tokenize(s) for s in sentences]\n",
        "\n",
        "# 2. Build vocabulary\n",
        "vocab = build_vocab_from_iterator(tokenized_sentences, specials=[\"<pad>\"])  #goes through all tokenized sentences and assigns unique integer IDs to each word. specials=[\"<pad>\"] → adds a padding token with index 0\n",
        "vocab.set_default_index(vocab[\"<pad>\"])  # unknown words → pad index\n",
        "\n",
        "# 3. Encode sentences\n",
        "encoded_sentences = [torch.tensor(vocab(s)) for s in tokenized_sentences] #Each word is replaced by its integer index using vocab(word_list), [\"i\", \"love\", \"this\", \"movie\"] → [1, 2, 3, 4]\n",
        "vocab_size = len(vocab)\n",
        "# 4. Pad sequences to same length\n",
        "#pad_sequence ensures all sentences have the same length, which is required to form a batch\n",
        "#batch_first=True → output shape will be (batch_size, max_len) instead of (max_len, batch_size)\n",
        "#padding_value=vocab[\"<pad>\"] → fills shorter sentences with 0 (padding token)\n",
        "padded_sentences = pad_sequence(encoded_sentences, batch_first=True, padding_value=vocab[\"<pad>\"])\n",
        "print(\"Padded Sentences:\\n\", padded_sentences)\n",
        "\n",
        "# Output: tensor of shape (batch_size, max_len)\n",
        "\n",
        "class SentimentRNN(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_size=32, hidden_size=64, output_size=2):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, emb_size, padding_idx=0)\n",
        "        self.rnn = nn.RNN(emb_size, hidden_size, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h0 = torch.zeros(1, x.size(0), 64)  # initial hidden state\n",
        "        x = self.embedding(x)               # (B, T, emb)\n",
        "        out, h = self.rnn(x, h0)           # out=(B, T, H)\n",
        "        out = out[:, -1, :]                 # take last hidden state\n",
        "        out = self.fc(out)                  # (B, output_size)\n",
        "        return out\n",
        "\n",
        "model = SentimentRNN(vocab_size)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "num_epochs = 200\n",
        "targets = torch.tensor(labels)\n",
        "for epoch in range(num_epochs):\n",
        "    optimizer.zero_grad()\n",
        "    logits = model(padded_sentences)\n",
        "    loss = criterion(logits, targets)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 50 == 0:\n",
        "        print(f\"Epoch {epoch} | Loss = {loss.item():.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lA1EfRaxpOE5",
        "outputId": "b3519504-7b57-44a5-eaa5-74be50f6eaf1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Padded Sentences:\n",
            " tensor([[2, 8, 1, 4],\n",
            "        [1, 5, 3, 6],\n",
            "        [2, 7, 1, 4],\n",
            "        [1, 3, 9, 0]])\n",
            "Epoch 0 | Loss = 0.6723\n",
            "Epoch 50 | Loss = 0.0000\n",
            "Epoch 100 | Loss = 0.0000\n",
            "Epoch 150 | Loss = 0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from datasets import load_dataset\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "\n",
        "# --------------------------------------------------\n",
        "# 1. Load IMDb small subset for safety\n",
        "# --------------------------------------------------\n",
        "data = load_dataset(\"imdb\")\n",
        "train_texts = data[\"train\"][\"text\"][:5000]   # take 5k for Colab safety\n",
        "train_labels = torch.tensor(data[\"train\"][\"label\"][:5000])\n",
        "\n",
        "MAX_LEN = 200  # limit review length\n",
        "\n",
        "\n",
        "# --------------------------------------------------\n",
        "# 2. Tokenizer\n",
        "# --------------------------------------------------\n",
        "def tokenize(s):\n",
        "    return s.lower().split()\n",
        "\n",
        "\n",
        "tokenized = [tokenize(s) for s in train_texts]\n",
        "\n",
        "\n",
        "# --------------------------------------------------\n",
        "# 3. Build vocabulary\n",
        "# --------------------------------------------------\n",
        "vocab = build_vocab_from_iterator(tokenized, specials=[\"<pad>\", \"<unk>\"])\n",
        "vocab.set_default_index(vocab[\"<unk>\"])\n",
        "PAD_IDX = vocab[\"<pad>\"]\n",
        "\n",
        "\n",
        "# --------------------------------------------------\n",
        "# 4. Encode + Truncate + Pad\n",
        "# --------------------------------------------------\n",
        "def encode(sentence):\n",
        "    ids = vocab(sentence)\n",
        "    ids = ids[:MAX_LEN]              # truncate\n",
        "    return torch.tensor(ids)\n",
        "\n",
        "\n",
        "encoded = [encode(s) for s in tokenized]\n",
        "\n",
        "padded = pad_sequence(\n",
        "    encoded,\n",
        "    batch_first=True,\n",
        "    padding_value=PAD_IDX\n",
        ")\n",
        "\n",
        "# ensure shape is (N, MAX_LEN)\n",
        "if padded.size(1) < MAX_LEN:  #If this is e.g. 180, but MAX_LEN=200, we still need 20 more paddings.\n",
        "    padded = torch.nn.functional.pad(\n",
        "        padded,\n",
        "        (0, MAX_LEN - padded.size(1)),\n",
        "        value=PAD_IDX\n",
        "    )\n",
        "\n",
        "\n",
        "dataset = torch.utils.data.TensorDataset(padded, train_labels) #TensorDataset is a PyTorch utility that allows you to pair tensors together and turn them into a dataset that can be used with a DataLoader\n",
        "#we use tensor dataset when data is already tensor, numbers and aligned proprerly. else we have to make custom dataset.\n",
        "loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "\n",
        "# --------------------------------------------------\n",
        "# 5. Define RNN model\n",
        "# --------------------------------------------------\n",
        "class SentimentRNN(nn.Module):\n",
        "    def __init__(self, vocab_size, emb=32, hidden=64, out=2):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, emb, padding_idx=PAD_IDX)\n",
        "        self.rnn = nn.RNN(emb, hidden, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden, out)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h0 = torch.zeros(1, x.size(0), 64)\n",
        "        x = self.embedding(x)\n",
        "        out, h = self.rnn(x, h0)\n",
        "        out = out[:, -1, :]    # last hidden state\n",
        "        return self.fc(out)\n",
        "\n",
        "\n",
        "model = SentimentRNN(len(vocab))\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.005)\n",
        "\n",
        "\n",
        "# --------------------------------------------------\n",
        "# 6. Training loop\n",
        "# --------------------------------------------------\n",
        "for epoch in range(5):     # keep small for demo\n",
        "    total_loss = 0\n",
        "    for batch_x, batch_y in loader:\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(batch_x)\n",
        "        loss = criterion(logits, batch_y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch} | Loss = {total_loss:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kRQ09H7-fSEH",
        "outputId": "b1dec0c3-0174-444d-8b63-59bb6860aa39"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 | Loss = 8.3994\n",
            "Epoch 1 | Loss = 0.2322\n",
            "Epoch 2 | Loss = 0.0108\n",
            "Epoch 3 | Loss = 0.0061\n",
            "Epoch 4 | Loss = 0.0040\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import torch\n",
        "\n",
        "def tokenize(s):\n",
        "    return s.lower().split()\n",
        "\n",
        "\n",
        "\n",
        "def encode(sentence):\n",
        "    ids = vocab(sentence)\n",
        "    ids = ids[:MAX_LEN]  # truncate\n",
        "    return torch.tensor(ids)\n",
        "\n",
        "def preprocess(text):\n",
        "    tokenized = tokenize(text)\n",
        "    encoded = encode(tokenized)\n",
        "\n",
        "\n",
        "    # pad to MAX_LEN\n",
        "    padded = torch.nn.functional.pad(\n",
        "        encoded,\n",
        "        (0, MAX_LEN - encoded.size(0)),\n",
        "        value=PAD_IDX\n",
        "    )\n",
        "\n",
        "    return padded.unsqueeze(0)   # shape (1, MAX_LEN)\n",
        "\n",
        "# --------------------------\n",
        "# PREDICTION\n",
        "# --------------------------\n",
        "\n",
        "with torch.no_grad():\n",
        "    review = input(\"Enter the review: \")\n",
        "\n",
        "    x = preprocess(review)\n",
        "\n",
        "    logits = model(x)\n",
        "    print(logits)\n",
        "\n",
        "    pred_class = torch.argmax(logits, dim=1).item()\n",
        "\n",
        "    if pred_class == 1:\n",
        "     print(\"POSITIVE\")\n",
        "    else:\n",
        "     print(\"NEGATIVE\")\n",
        "\n",
        "\n",
        "#this is a very simple model and hence this will not give correct output. so , lstm is rerquired since rnn cannot remember long term datas\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2bpcIv7Vggx0",
        "outputId": "154c4565-7ad8-4f50-8573-c2844a6f590d"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the review: its not okay\n",
            "tensor([[ 5.5799, -5.1940]])\n",
            "NEGATIVE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#start of lstm"
      ],
      "metadata": {
        "id": "jNJoPLyCnlFy"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TYcKpK2YlqH9",
        "outputId": "3a9d3a77-64ea-4560-e82d-6dd8e886b46e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.3)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2025.11.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "from collections import Counter\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "Bzl5P_NtaZCr"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "document = \"\"\"About the Program\n",
        "What is the course fee for  Data Science Mentorship Program (DSMP 2023)\n",
        "The course follows a monthly subscription model where you have to make monthly payments of Rs 799/month.\n",
        "What is the total duration of the course?\n",
        "The total duration of the course is 7 months. So the total course fee becomes 799*7 = Rs 5600(approx.)\n",
        "What is the syllabus of the mentorship program?\n",
        "We will be covering the following modules:\n",
        "Python Fundamentals\n",
        "Python libraries for Data Science\n",
        "Data Analysis\n",
        "SQL for Data Science\n",
        "Maths for Machine Learning\n",
        "ML Algorithms\n",
        "Practical ML\n",
        "MLOPs\n",
        "Case studies\n",
        "You can check the detailed syllabus here - https://learnwith.campusx.in/courses/CampusX-Data-Science-Mentorship-Program-637339afe4b0615a1bbed390\n",
        "Will Deep Learning and NLP be a part of this program?\n",
        "No, NLP and Deep Learning both are not a part of this program’s curriculum.\n",
        "What if I miss a live session? Will I get a recording of the session?\n",
        "Yes all our sessions are recorded, so even if you miss a session you can go back and watch the recording.\n",
        "Where can I find the class schedule?\n",
        "Checkout this google sheet to see month by month time table of the course - https://docs.google.com/spreadsheets/d/16OoTax_A6ORAeCg4emgexhqqPv3noQPYKU7RJ6ArOzk/edit?usp=sharing.\n",
        "What is the time duration of all the live sessions?\n",
        "Roughly, all the sessions last 2 hours.\n",
        "What is the language spoken by the instructor during the sessions?\n",
        "Hinglish\n",
        "How will I be informed about the upcoming class?\n",
        "You will get a mail from our side before every paid session once you become a paid user.\n",
        "Can I do this course if I am from a non-tech background?\n",
        "Yes, absolutely.\n",
        "I am late, can I join the program in the middle?\n",
        "Absolutely, you can join the program anytime.\n",
        "If I join/pay in the middle, will I be able to see all the past lectures?\n",
        "Yes, once you make the payment you will be able to see all the past content in your dashboard.\n",
        "Where do I have to submit the task?\n",
        "You don’t have to submit the task. We will provide you with the solutions, you have to self evaluate the task yourself.\n",
        "Will we do case studies in the program?\n",
        "Yes.\n",
        "Where can we contact you?\n",
        "You can mail us at nitish.campusx@gmail.com\n",
        "Payment/Registration related questions\n",
        "Where do we have to make our payments? Your YouTube channel or website?\n",
        "You have to make all your monthly payments on our website. Here is the link for our website - https://learnwith.campusx.in/\n",
        "Can we pay the entire amount of Rs 5600 all at once?\n",
        "Unfortunately no, the program follows a monthly subscription model.\n",
        "What is the validity of monthly subscription? Suppose if I pay on 15th Jan, then do I have to pay again on 1st Feb or 15th Feb\n",
        "15th Feb. The validity period is 30 days from the day you make the payment. So essentially you can join anytime you don’t have to wait for a month to end.\n",
        "What if I don’t like the course after making the payment. What is the refund policy?\n",
        "You get a 7 days refund period from the day you have made the payment.\n",
        "I am living outside India and I am not able to make the payment on the website, what should I do?\n",
        "You have to contact us by sending a mail at nitish.campusx@gmail.com\n",
        "Post registration queries\n",
        "Till when can I view the paid videos on the website?\n",
        "This one is tricky, so read carefully. You can watch the videos till your subscription is valid. Suppose you have purchased subscription on 21st Jan, you will be able to watch all the past paid sessions in the period of 21st Jan to 20th Feb. But after 21st Feb you will have to purchase the subscription again.\n",
        "But once the course is over and you have paid us Rs 5600(or 7 installments of Rs 799) you will be able to watch the paid sessions till Aug 2024.\n",
        "Why lifetime validity is not provided?\n",
        "Because of the low course fee.\n",
        "Where can I reach out in case of a doubt after the session?\n",
        "You will have to fill a google form provided in your dashboard and our team will contact you for a 1 on 1 doubt clearance session\n",
        "If I join the program late, can I still ask past week doubts?\n",
        "Yes, just select past week doubt in the doubt clearance google form.\n",
        "I am living outside India and I am not able to make the payment on the website, what should I do?\n",
        "You have to contact us by sending a mail at nitish.campusx@gmai.com\n",
        "Certificate and Placement Assistance related queries\n",
        "What is the criteria to get the certificate?\n",
        "There are 2 criterias:\n",
        "You have to pay the entire fee of Rs 5600\n",
        "You have to attempt all the course assessments.\n",
        "I am joining late. How can I pay payment of the earlier months?\n",
        "You will get a link to pay fee of earlier months in your dashboard once you pay for the current month.\n",
        "I have read that Placement assistance is a part of this program. What comes under Placement assistance?\n",
        "This is to clarify that Placement assistance does not mean Placement guarantee. So we dont guarantee you any jobs or for that matter even interview calls. So if you are planning to join this course just for placements, I am afraid you will be disappointed. Here is what comes under placement assistance\n",
        "Portfolio Building sessions\n",
        "Soft skill sessions\n",
        "Sessions with industry mentors\n",
        "Discussion on Job hunting strategies\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "NWNi0EeRmVaI"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"punkt_tab\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wSwM5R6BmZ05",
        "outputId": "3cf7df8f-d731-4c39-8726-b0d79566b68c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = word_tokenize(document.lower())"
      ],
      "metadata": {
        "id": "RWLEMEramrzJ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# build vocab\n",
        "vocab = {'<unk>':0}\n",
        "\n",
        "#Counter(token).keys() #provides info of how many tme same word has arrived in a data. .keys() filters uniques words form the tokens\n",
        "\n",
        "for token in Counter(tokens).keys():\n",
        "  if token not in vocab:\n",
        "    vocab[token] = len(vocab)\n",
        "\n",
        "len(vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lBxOBg_gsC_g",
        "outputId": "29fc7715-da8c-40ff-8e00-adcd61a068e3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "289"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_sentences = document.split('\\n')"
      ],
      "metadata": {
        "id": "YPFXKZIjsYp3"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def text_to_indces(sentence,vocab):\n",
        "  numerical_sentence = []\n",
        "\n",
        "  for token in sentence:\n",
        "    if token in vocab:\n",
        "      numerical_sentence.append(vocab[token])\n",
        "    else:\n",
        "      numerical_sentence.append(vocab['<unk>'])\n",
        "\n",
        "  return numerical_sentence\n",
        "\n"
      ],
      "metadata": {
        "id": "kRAH6I0pu9Gp"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_numerical_sentences = []\n",
        "for sentence in input_sentences:\n",
        "  input_numerical_sentences.append(text_to_indces(word_tokenize(sentence.lower()),vocab))\n",
        "\n",
        "print(len(input_numerical_sentences))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3G49k-E_4s97",
        "outputId": "7ef4c286-196a-41d6-8dcf-2ee9b49cc928"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "78\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_sequence = []\n",
        "for sentence in input_numerical_sentences:\n",
        "  for i in range (1,len(sentence)):\n",
        "    training_sequence.append(sentence[:i+1])\n",
        "\n",
        "print(len(training_sequence))\n",
        "\n",
        "\n",
        "\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bshsYrA2GY_y",
        "outputId": "885faeec-5c98-4e82-d9d2-16f6988485cb"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "942\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len_list = []\n",
        "\n",
        "for sequence in training_sequence:\n",
        "  len_list.append(len(sequence))\n",
        "\n",
        "max(len_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jrel-bVaKppj",
        "outputId": "83928b6c-395c-48b3-a917-d7e43bd7c14e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "62"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "padded_training_sequence = []\n",
        "\n",
        "for sequence in training_sequence:\n",
        "  padded_training_sequence.append([0]*(max(len_list)-len(sequence))+sequence)\n",
        "\n"
      ],
      "metadata": {
        "id": "cTlVcRBBLLXI"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "padded_training_sequence = torch.tensor(padded_training_sequence, dtype=torch.long)"
      ],
      "metadata": {
        "id": "2uuALKonMFnJ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = padded_training_sequence[:, :-1] #all rows, all columns except last one\n",
        "\n",
        "y = padded_training_sequence[:, -1] #all rows and only last column\n",
        "\n",
        "print(X.shape)\n",
        "print(y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-rC_jDIMHYg",
        "outputId": "15f49b8b-88e3-4ad4-d929-f8b45bdc6735"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([942, 61])\n",
            "torch.Size([942])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "\n",
        "  def __init__(self, X, y):\n",
        "    self.X = X\n",
        "    self.y = y\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.X.shape[0]\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.X[idx], self.y[idx]"
      ],
      "metadata": {
        "id": "55ASLfo7UC_P"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = CustomDataset(X, y)\n",
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n"
      ],
      "metadata": {
        "id": "YPjzuI-lUPVG"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMModel(nn.Module):\n",
        "\n",
        "  def __init__(self, vocab_size):\n",
        "    super().__init__()\n",
        "    self.embedding = nn.Embedding(vocab_size, 100)\n",
        "    self.lstm = nn.LSTM(100, 150, batch_first=True)\n",
        "    self.fc = nn.Linear(150, vocab_size)\n",
        "\n",
        "  def forward(self, x):\n",
        "    embedded = self.embedding(x)\n",
        "    intermediate_hidden_states, (final_hidden_state, final_cell_state) = self.lstm(embedded)\n",
        "    output = self.fc(final_hidden_state.squeeze(0))\n",
        "    return output"
      ],
      "metadata": {
        "id": "NAcdX5WZU9LE"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LSTMModel(len(vocab))\n"
      ],
      "metadata": {
        "id": "tzZ1I11IZqLY"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "FutQMsnYZthc"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1yHGDbU3ZuuW",
        "outputId": "8214f609-f329-42a9-a12a-3e321ff57255"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTMModel(\n",
              "  (embedding): Embedding(289, 100)\n",
              "  (lstm): LSTM(100, 150, batch_first=True)\n",
              "  (fc): Linear(in_features=150, out_features=289, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 50\n",
        "learning_rate = 0.001\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "CaWLeh9yZxQW"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "  total_loss = 0\n",
        "  for batch_x, batch_y in dataloader:\n",
        "    batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    output = model(batch_x)\n",
        "\n",
        "    loss = criterion(output, batch_y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    total_loss = total_loss + loss.item()\n",
        "\n",
        "  print(f\"Epoch: {epoch + 1}, Loss: {total_loss:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v0imidtHZ18t",
        "outputId": "2e67dbba-8a7f-44c9-903b-3a733fabc8dd"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Loss: 165.7803\n",
            "Epoch: 2, Loss: 146.3346\n",
            "Epoch: 3, Loss: 132.8596\n",
            "Epoch: 4, Loss: 120.3049\n",
            "Epoch: 5, Loss: 107.8165\n",
            "Epoch: 6, Loss: 96.5075\n",
            "Epoch: 7, Loss: 85.7729\n",
            "Epoch: 8, Loss: 76.0596\n",
            "Epoch: 9, Loss: 67.2163\n",
            "Epoch: 10, Loss: 59.1027\n",
            "Epoch: 11, Loss: 52.2223\n",
            "Epoch: 12, Loss: 45.1960\n",
            "Epoch: 13, Loss: 39.5912\n",
            "Epoch: 14, Loss: 34.7385\n",
            "Epoch: 15, Loss: 30.5709\n",
            "Epoch: 16, Loss: 26.8089\n",
            "Epoch: 17, Loss: 23.6598\n",
            "Epoch: 18, Loss: 21.0076\n",
            "Epoch: 19, Loss: 18.5686\n",
            "Epoch: 20, Loss: 16.5265\n",
            "Epoch: 21, Loss: 14.8247\n",
            "Epoch: 22, Loss: 13.4261\n",
            "Epoch: 23, Loss: 12.4555\n",
            "Epoch: 24, Loss: 11.2217\n",
            "Epoch: 25, Loss: 10.4985\n",
            "Epoch: 26, Loss: 9.8627\n",
            "Epoch: 27, Loss: 9.1081\n",
            "Epoch: 28, Loss: 8.5982\n",
            "Epoch: 29, Loss: 8.0761\n",
            "Epoch: 30, Loss: 7.5909\n",
            "Epoch: 31, Loss: 7.2411\n",
            "Epoch: 32, Loss: 6.8953\n",
            "Epoch: 33, Loss: 6.6012\n",
            "Epoch: 34, Loss: 6.2888\n",
            "Epoch: 35, Loss: 5.9832\n",
            "Epoch: 36, Loss: 5.9597\n",
            "Epoch: 37, Loss: 5.8327\n",
            "Epoch: 38, Loss: 5.5972\n",
            "Epoch: 39, Loss: 5.4030\n",
            "Epoch: 40, Loss: 5.2363\n",
            "Epoch: 41, Loss: 5.1340\n",
            "Epoch: 42, Loss: 5.0316\n",
            "Epoch: 43, Loss: 5.0781\n",
            "Epoch: 44, Loss: 4.8683\n",
            "Epoch: 45, Loss: 4.6262\n",
            "Epoch: 46, Loss: 4.5563\n",
            "Epoch: 47, Loss: 4.5900\n",
            "Epoch: 48, Loss: 4.5555\n",
            "Epoch: 49, Loss: 4.4730\n",
            "Epoch: 50, Loss: 4.3078\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def prediction(model,vocab,text):\n",
        "  tokenized_text = word_tokenize(text.lower())\n",
        "  numerical_text = text_to_indces(tokenized_text,vocab)\n",
        "  padded_text = torch.tensor([0] * (61 - len(numerical_text)) + numerical_text, dtype=torch.long).unsqueeze(0)\n",
        "  output = model(padded_text)\n",
        "  value, index = torch.max(output, dim=1)\n",
        "  print(index)\n",
        "  return text + \" \" + list(vocab.keys())[index]\n"
      ],
      "metadata": {
        "id": "roNFSf8kdwD3"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction(model, vocab, \"The course\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "55MEzc6bg9X6",
        "outputId": "165de482-5437-4e85-cd2e-7064f911f98e"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([16])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The course follows'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from datasets import load_dataset\n",
        "\n",
        "from collections import Counter\n",
        "from nltk.tokenize import word_tokenize\n",
        "import numpy as np\n",
        "# --------------------------------------------------\n",
        "# 1. Load IMDb small subset for safety\n",
        "# --------------------------------------------------\n",
        "data = load_dataset(\"imdb\")\n",
        "train_texts_lines = data[\"train\"][\"text\"][5000:20000]   # take 5k for Colab safety\n",
        "train_labels = torch.tensor(data[\"train\"][\"label\"][5000:20000])\n",
        "print(train_labels.bincount())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WsIh2-iAFhvs",
        "outputId": "fb1e3791-b9ef-49f7-c70b-da20f3f867fe"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([7500, 7500])\n"
          ]
        }
      ]
    }
  ]
}